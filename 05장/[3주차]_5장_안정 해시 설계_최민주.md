# 해시 키 재배치(rehash) 문제

특정한 키가 보관된 서버를 알아내기 위해, 모듈러 연산을 `hash(key) % N`과 같이 적용한다. (N은 서버의 개수이다)

서버 풀(server pool)의 크기가 고정되어 있을 때, 그리고 데이터 분포가 균등할 때는 잘 동작한다.

하지만 서버가 추가되거나 기존 서버가 삭제되면 문제가 생긴다. 

> 💥 이 문제가 바로 우리가 이번 단원에서 살펴볼 "안정 해시"의 시발점이다.

<br>

예를 들어,

- 0, 1, 2, 3번 서버가 존재한다. 이 때 키가 보관된 서버를 알기 위한 모듈러 연산은 `hash(key) % 4`이다.
- 1번 서버가 장애를 일으켜 동작을 중단하면, 서버 풀의 크기는 3으로 바뀔 것이다.
- 그 결과 모듈러 연산은 `hash(key) % 3`으로 바뀐다.
- 바뀐 모듈러 연산에 의해, 장애가 발생한 1번 서버에 보관되어 있던 키 뿐만 아니라 대부분의 키가 재분배된다.
- 1번 서버가 죽으면 대부분 캐시 클라이언트가 데이터가 없는 엉뚱한 서버에 접속하게 되고, 대규모 캐시 미스(cache miss)가 발생한다. 

이런 문제를 효과적으로 해결하는 기술이 바로 "안정 해시"이다.

# 안정 해시 (consistent hash)

안정 해시는 해시 테이블 크기가 조정될 때 평균적으로 오직 k/n개의 키만 재배치하는 해시 기술이다. (k는 키의 개수, n은 슬롯의 개수)

> [참고](https://www.youtube.com/watch?v=mPB2CZiAkKM&t=3580s)

이와 달리 대부분의 전통적 해시 테이블은 슬롯의 수가 바뀌면 거의 대부분 키를 재배치한다.

## 해시 공간과 해시 링
안정 해시의 동작 원리에 대해 살펴보자.

해시 함수 f로는 SHA-1을 사용한다고 가정하자. SHA-1의 해시 공간(hash space) 범위는 0부터 2^160-1까지라고 알려져 있다.

아래 그림은 이 해시 공간을 그림으로 표현한 것이다.

<img width="794" alt="스크린샷 2024-07-09 오후 9 37 14" src="https://github.com/11th-SSAFY-19/large-scale-system-design/assets/59405576/8e99e794-6399-4b12-b673-631cf3053ec3">

이 해시 공간의 양쪽을 구부려 접으면 아래와 같은 해시 링(hash ring)이 만들어진다.

<img width="460" alt="스크린샷 2024-07-09 오후 9 37 27" src="https://github.com/11th-SSAFY-19/large-scale-system-design/assets/59405576/6fe0fe30-6a4a-4a77-97c9-419a9294a100">

## 해시 서버

이 해시 함수 f를 사용하면 서버 IP나 이름을 링 위의 어떤 위치에 대응시킬 수 있다. 아래는 4개의 서버를 해시 링 위에 배치한 결과다.

<img width="389" alt="스크린샷 2024-07-09 오후 9 41 49" src="https://github.com/11th-SSAFY-19/large-scale-system-design/assets/59405576/fa38ae01-63c2-4361-9c32-048adc1fa376">

## 해시 키 

여기서 사용된 해시 함수는 "해시 키 재배치 문제"에 언급된 함수와는 다르며, 모듈러 연산(%)은 사용하지 않고 있음에 유의하자.

아래 그림과 같이 캐시할 키 key0, key1, key2, key3 또한 해시 링 위의 어느 지점에 배치할 수 있다. 

<img width="449" alt="스크린샷 2024-07-09 오후 9 45 52" src="https://github.com/11th-SSAFY-19/large-scale-system-design/assets/59405576/f89be4be-860e-44f8-9b8a-065b102c8d2a">

## 서버 조회

어떤 서키가 저장되는 서버는, 해당 키의 위치로부터 시계 방향으로 링을 탐색해 나가면서 만나는 첫 번째 서버다. 

따라서 key0은 서버 0에 저장되고, key1은 서버 1에 저장되며, key2는 서버 2, key3은 서버 3에 저장된다.

<img width="539" alt="스크린샷 2024-07-09 오후 9 49 31" src="https://github.com/11th-SSAFY-19/large-scale-system-design/assets/59405576/97746bc4-c51a-48a6-9862-8af5d3054f09">

## 서버 추가

아래 그림을 보면, 새로운 서버 4가 추가된 뒤에 key1만 재배치된다. k0, k2, k3는 같은 서버에 남는다.

<img width="600" alt="스크린샷 2024-07-09 오후 9 55 24" src="https://github.com/11th-SSAFY-19/large-scale-system-design/assets/59405576/616d3e4e-d208-483d-87bd-7cb1891eba29">

왜 그런지 자세히 살펴보자.

서버 4가 추가되기 전, key1은 서버 1에 저장되어 있었다. 하지만 서버 4가 추가된 뒤에 key1은 서버 4에 저장될 것인데, 왜냐하면 key1의 위치에서 시계 방향으로 순회했을 때 처음으로 만나게 되는 서버가 서버 4이기 때문이다.

따라서 다른 키들은 재배치되지 않는 것이다.

## 서버 제거

하나의 서버가 제거되면 키 가운데 일부만 재배치된다.

아래 그림에서, 서버 1이 삭제되었을 때 key1만이 서버 2로 재배치됨을 알 수 있다. 나머지 키에는 영향이 없다.

<img width="551" alt="스크린샷 2024-07-09 오후 9 59 51" src="https://github.com/11th-SSAFY-19/large-scale-system-design/assets/59405576/acf2886a-cb2d-408d-a896-10fb99f57b61">

## 안정 해시를 구현하는 기본 절차의 두 가지 문제

안정 해시 알고리즘의 기본 절차는 다음과 같다.

- 서버와 키를 균등 분포 해시 함수를 사용해 해시 링에 배치한다.
- 키의 위치에서 링을 시계 방향으로 탐색하다 만나는 최초의 서버가 키가 저장될 서버다.

이 접근법에는 두 가지 문제가 있다.

1. 서버가 추가되거나 삭제되는 상황을 감안하면 파티션의 크기를 균등하게 유지하는 게 불가능하다.

여기서 파티션은 인접한 서버 사이의 해시 공간이다. <br>
어떤 서버는 굉장히 작은 해시 공간을 할당 받고, 어떤 서버는 굉장히 큰 해시 공간을 할당 받는 상황이 가능하다.

아래 예시를 보자.

<img width="850" alt="스크린샷 2024-07-10 오전 8 11 08" src="https://github.com/11th-SSAFY-19/large-scale-system-design/assets/59405576/d86a3612-b355-4953-a3c6-6ab0cd8d079c">

서버 1이 삭제되는 바람에 서버 2의 파티션이 다른 파티션 대비 두 배로 커지는 상황을 보여준다.

2. 키의 균등 분포를 달성하기가 어렵다.

아래 상황에서 서버 3은 아무 데이터도 갖지 않는 반면, 대부분의 키는 서버 2에 보관될 것이다.

<img width="427" alt="스크린샷 2024-07-10 오전 8 14 30" src="https://github.com/11th-SSAFY-19/large-scale-system-design/assets/59405576/be8c6272-1cf0-421a-9c58-93e6fa9a46ac">

이 문제를 해결하기 위해 제안된 기법이 가상 노드(virtual node) 또는 복제(replica)라 불리는 기법이다.

## 가상 노드 (virtual node)

가상 노드는 실제 노드 또는 서버를 가리키는 노드로서, 하나의 서버는 링 위에 여러 개의 가상 노드를 가질 수 있다.

아래 그림을 보면, 서버 0을 링에 배치하기 위해 s0 하나만 쓰는 대신, `s0_0`, `s0_1`, `s0_2` 세 개의 가상 노드를 사용하였다. 마찬가지로 서버 1도 세 개의 가상 노드를 사용했다.

키의 위치로부터 시계 방향으로 링을 탐색하다 만나는 최초의 가상 노드가 가리키는 서버가 해당 키가 저장될 서버가 된다.

예를 들어, k0이 저장되는 서버는 k0의 위치로부터 링을 시계 방향으로 탐색하다 만나는 최초의 가상 노드 s1_0이 가리키는 서버, 즉 서버 1이다.

<img width="649" alt="스크린샷 2024-07-10 오전 8 30 25" src="https://github.com/11th-SSAFY-19/large-scale-system-design/assets/59405576/dadeb7f2-877a-4f93-9171-da325a98d730">

위와 같이 가상 노드를 사용하면, 각 서버는 하나가 아닌 여러 개의 파티션을 관리해야 한다. 

> 예시에서는 각 서버의 가상 노드를 3개로 정했지만, 실제 시스템에서는 그보다 훨씬 큰 값이 사용된다. 

가상 노드의 개수르르 늘리면 키의 분포는 점점 더 균등해진다. 표준 편차가 작아져서 데이터가 고르게 분포되기 때문이다.

하지만 가상 노드를 늘리면 늘릴수록 가상 노드 데이터를 저장할 공간이 더 많이 필요하게 된다. tradeoff가 필요하다!

## 재배치할 키 결정

서버가 추가되거나 제거되면 데이터 일부는 재배치해야 한다. 어느 범위의 키들이 제배치되어야 할까?

아래 예시처럼 서버 4가 새롭게 추가되었다고 하자. 이에 영향 받은 범위는 s4(새로 추가된 노드)부터 그 반시계 방향에 있는 첫 번째 서버인 s3까지이다.

즉, s3부터 s4 사이에 있는 키들은 s4로 재배치하여야 한다.

<img width="428" alt="스크린샷 2024-07-10 오후 11 10 07" src="https://github.com/11th-SSAFY-19/large-scale-system-design/assets/59405576/bf317e1e-02fd-4ba0-93d8-d0e104c2d839">

이번에는 서버가 삭제된 경우를 살펴보자.

아래와 같이 s1이 삭제되면 s1(삭제된 노드)부터 그 반시계 방향에 있는 최초 서버 s0 사이에 있는 키들이 s2로 재배치 되어야 한다.

<img width="387" alt="스크린샷 2024-07-10 오후 11 14 16" src="https://github.com/11th-SSAFY-19/large-scale-system-design/assets/59405576/dd65327e-857c-4a2f-922c-837e6e4f125c">

<br>

# 마치며

이번 장에서 살펴본 안정 해시의 이점은 다음과 같다.

- 서버가 추가되거나 삭제될 때, 재배치되는 키의 수가 최소화된다.
- 데이터가 균등하게 분배되므로, 수평적 규모 확장성을 달성하기 쉽다.
- 핫스팟 키 문제를 줄인다. 
  - 핫스팟 키 문제는 특정 샤드에 유명인의 데이터가 몰리는 상황에서, 특정 샤드에 대한 접근이 지나치게 빈번하여 서버 과부하가 발생하는 문제이다. 안정 해시를 이용해 데이터를 더 균등하게 분배할 수 있다. 



