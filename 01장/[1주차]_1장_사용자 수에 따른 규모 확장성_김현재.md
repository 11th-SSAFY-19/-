# 개요
 대량의 트래픽이 들어오는 경우 어떤 식으로 처리할 것인가 는 물론 개발자로서 항상 고민해야할 주제이다. 
 이에 대한 부분에 대해서 이론적으로 정리하기 위한 글을 작성해보기러 결심하였다. 주 교재는 가상면접 사례로 배우는 대규모 시스템 설계 기초라는 책으로 하겠다.

<br>
<br>
 
 # 본문
 ### 단일 서버

 단일 서버 같은 경우 우리가 일반적으로 이용하는 아키텍트이다. 예전에 프로젝트에 이용했던 구조인데 대충 저런 식으로 단일 서버를 사용하는데 사용한다.
 
WAS: 웹 애플리케이션 서버를 통해서 비즈니스 로직, 데이터 저장 등을 한다. 이 과정에서 단일 서버를 이용한다면 WAS 서버를 하나만 가지고 갈 수 있을 것이다. DB 같은 경우도 물론 하나의 DB만 사용하게 될 것이다. 

>
>
어떤 DB를 사용할 것인가?
>
관계형 DB는 자료를 테이블과 열, 칼럼으로 표현한다. SQL을 사용하면 여러 테이블에 있는 데이터를 그 관계에 따라 조인하여 합칠 수 있다.
>
비관계형 DB는 NoSQL이라고도 부른다. 키-값 저장소, 그래프 저장소, 칼럼 저장소, 문서 저장소가 그것이다. 비-관계형 데이터 베이스는 일반적으로 조인 연산은 지원하지 않는다. 
>
비관계형 DB가 바람직한 선택일 수 있다.
- 아주 낮은 응답 지연시간이 요구된다.
- 다루는 데이터가 비정형이라 관계형 DB가 아님
- 데이터를 직렬화하거나 역직렬화 할 수 있기만 하면 됨
아주 많은 양의 데이터를 저장할 필요가 있음 

---

### 수직적 규모 확장 vs 수평적 규모 확장 
- Scale up 은 수직적 규모 확장 프로세스는 고사양을 추가하는 행위를 말한다. 
- Scale out 은 수평적 규모 확장 프로세스로 더 많은 서버를 추가하여 성능을 개선하는 행위이다.

수직적 규모는 구조의 단순함이 장점이지만 반면 한 대의 서버에 늘리는 방식은 한계가 있고 다중화가 않되기 때문에 가용성이 떨어진다.

너무 많은 사용자가 접속하여 웹 서버가 한계 상황에 도달하면 응답 속도가 느려지거나 서버 접속이 불가능해 질 수도 있다. 이런 문제를 해결하는 데는 부하 분산기 똔느 로드 밸런서를 도입하는 것이 최선이다.

---

### 로드 밸런서
![](https://velog.velcdn.com/images/khjmr98/post/20a569be-f39d-4df5-9a4c-7a905790a6df/image.png)
로드 밸런서는 부하 분산 집합에 속한 웹 서버들에게 트래픽 부하를 고르게 분산하는 역할을 한다. 
사용자는 로드 밸런서의 공개 IP 주소로 접속한다. 웹 서버는 클라이언트접속을 직접 처리하지 않고 더 나은 보안을 위해, 서버 간 통신에는 사설 IP 주소가 이용된다. 사설 IP 주소는 같은 네트워크에 속한 서버 사이의 통신에만 쓰일 수 있는 IP 주소로, 인터넷을 통해서는 접속 불가능하다.

웹 계층은 로드 밸런서를 이용한 분산을 통해서 서버의 장애 혹은 일시적인 트래픽 장애에 대해 유연한 대처가 가능해진다.

하지만 데이터 베이스 다중화는 불가능하다.

---

### 데이터 베이스 다중화 
![](https://velog.velcdn.com/images/khjmr98/post/bcbdb57a-36b3-4788-8d9e-ffed714a20ca/image.png)

많은 데이터베이스 관리 시스템이 다중화를 지원한다. 서버 사이에 주-부 관계를 설정하고 데이터는 원본 서버에, 사본은 부 서버에 저장하는 방식이다.

쓰기 연산은 마스터에서만 지원한다. 부 데이터 베이스는 주 데이터 베이스로부터 그 사본을 전달받으며, 읽기 연산만을 지원한다. 

- 더 나은 성능: 주-부 다중화 모델에서 모든 데이터 변경 연산은 주 데이터 베이스 서버로만 전달되는 반면 읽기 연산은 부 데이터 베이스 서버들로 분산 된다.
- 안정성: 데이터가 보존된다. 데이터를 지역적으로 떨어진 여러 장소에 다중화시켜 놓을 수 있다.
- 가용성: 데이터를 여러 지역에 복제해 둠으로써, 하나의 데이터 서버에 장애가 발생하더라도 다른 서버에 있는 데이터를 가져와 계속 서비스할 수 있게 된다.

장애가 생길 경우를 두 가지로 나누어 생각해보자.
- 부 서버가 한 대 뿐인데 다운된 경우라면, 읽기 연산이 모두 주 데이터베이스로 전달될 것이다. 
- 부 서버가 여러 대인 경우에 다운된다면 읽기 연산은 나머지 부 데이터 베이스 서버들로 분산될 것이며, 새로운 부 데이터 베이스 서버가 장애 서버를 대체한다.
- 주 데이터 베이스 서버가 다운되면, 한 대의 부 데이터 베이스만 있는 경우 해당 부 데이터베이스 서버가 새로운 주 서버가 될 것이다. 모든 데이터 베이스 연산은 일시적으로 새로운 주 서버 상에서 수행될 것이다. 
하지만 실제 프로덕트 상에서는 부 서버와 주 서버의 상태가 안 맞을 수도 있으므로 없는 데이터는 복구 스크립트를 돌려서 추가해야한다. 다중 마스터나 원형 다중화 방식을 도입하면 이런 상황에 대처하는 데 도움이 될 수도 있다. 

---
### 캐시

캐시는 값비싼 연산 결과 또는 자주 참조되는 데이터를 메모리 안에 두고, 뒤이은 요청이 보다 빨리 처리될 수 있도록 하는 저장소이다. 

**캐시 계층**
캐시 계층은 데이터가 잠시 보관되는 곳으로 데이터베이스보다 훨씬 빠르다. 별도의 캐시 계층을 두면 성능이 개선될 뿐 아니라 데이터의 부하를 줄일 수 있다. 캐시 계층의 규모를 독립적으로 확장도 가능하다. 

캐시 저장 방법의 몇 가지 방식에 대해서는 나중에 정리하겠다.

**캐시 사용시 유의할 점**

- 캐시 사용이 적절할 때: 데이터 갱신은 자주 일어나지 않지만 참조는 빈번하게 일어난다면 고려하자.
- 어떤 데이터를 캐시에 저장할 것인지: 캐시는 데이터를 휘발성 메모리에 두므로, 영속적으로 보관할 데이터를 캐시에 두는 것은 바람직하지 않다. 중요한 데이터는 지속적 저장소에 저장하자.
- 캐시에 보관된 데이터는 어떻게 만료되는가?: 캐시 데이터는 만 시 삭제되어야한다. 만료 기한이 너무 짧으면 데이터를 너무 자주 읽게 되므로 문제가 발생하고, 만료 기한이 너무 길면 원본과 차이점이 날 가능성이 크다. 
- 일관성은 유지도 신경쓸 요소중 하나이다. 일관성은 데이터 저장소의 원본과 캐시 내의 사본이 같은지 여부다. 
저장소의 원본을 갱신하는 연산과 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되지 않는 경우 일관성은 깨질 수 있다. 여러 지역에 걸쳐 시스템을 확장해 나가는 경우 캐시와 저장소 사이의 일관성을 유지하는 것은 어려운 문제이다.
- 장애 대처: 캐시 서버를 한 대만 두는 경우 해당 서버는 단일 장애 지점이 되어 버릴 수 있다. 특정 지점의 장애가 생길 시 전체 시스템이 멈출 수도 있다는 뜻이다. 여러 지역에 캐시를 두는 것이 건강한 캐시 시스템이 된다.
- 캐시 메모리 크기: 캐시 메모리 크기가 너무 작으면 액세스 패턴에 따라서는 데이터가 너무 자주 캐시에 서 밀려나버려서 캐시의 성능이 떨어지게 된다. 캐시 메모리를 과할당 하는 것이 대처법이긴하다.
- 데이터 방출: 캐시가 꽉 차버릴 시 기존 데이터를 내보내야 한다. 캐시 데이터 방출 정책이라 하는데, 그 가운데 가장 널리 쓰이는 것은 LRU이다. 다른 정책으로는 LFU, FIFO 같은 것도 있으며, 경우에 적용 가능하다.

---
### CDN
![](https://velog.velcdn.com/images/khjmr98/post/3b722ea6-7cc1-4bc4-8a68-bc47eb6964d3/image.png)

CDN은 정적 콘텐츠를 전송하는 데 쓰이는, 지리적으로 분산된 서버의 네트워크이다. 
CDN 이 어떻게 동작하는지를 개략적으로만 살펴보면 다음과 같다. 

**CDN 이 사용 시 고려해야 할 사항**
- 비용: CDN은 보통 3 사업자 의해 운영되며, 여러 분은 CDN으로 들어가고 나가는 데이터 전송 양에 따라 요금을 내게 된다.
- 적절한 만료 시한 설정: 시의성이 중요한 콘텐ㅌ츠의 경우 만료 시점을 잘 정해야 한다. 너무 길지도 않고 짧지도 않아야한다.
- CDN 장애에 대한 대처 방안: CDN 자체가 죽었을 경우 원본 서버로 향하도록 한다던가 하는 방법을 사용해야한다.
- 콘텐츠 무효화 방법: 아직 만료되지 않은 콘텐츠라 하더라도 CDN에서 제거할 수 있어야한다.
  - CDN 서비스 사업자가 제공하는 API 이용하여 콘텐츠 무효화
  - 콘텐츠 다른 버전 서비스하도록 오브젝트 버저닝 이용
  
---
### 무상태(stateless) 웹계층
웹 계층을 수평적으로 확장하는 방법을 고민해 볼 순서이다.
바람직한 전략은 상태 정보를 관계형 데이터베이스나 NoSQL 같은 지속성 저장소에 보관하고, 필요할 때 가져오도록 하는 것이다.

<br>

**지속성 있는 서버일 때**
만약 지속성을 유지하고자 하면 sticky session 이라고 하는 항상 같은 사용자에 대한 요청을 특정 서버로 보내는 방법을 사용해야하는데, 이는 scale out 을 하기 썩 좋은 방법은 아니다. 장애 시에 대처도 힘들기 때문이다.

<br>

**무상태 아키텍처**
상태 정보가 필요할 경우 공유 저장소로부터 데이터를 가져온다. 상태 정보는 웹 서버로부터 물리적으로 분리되어 있다. 이런 구조는 단순하고, 안정적이며, 규모 확장이 쉽다.

---
### 데이터 센터
두 개의 데이터 센터를 이용할 시에는 장애가 없을 시 지역에 따라서 가장 가까운 데이터 센터로 안내된다. 이 절차를 지리적 라우팅이라 부른다.
가령 두 개의 데이터 센터가 있을 시 x% 사용자는 특정 지역 센터로 나머지 (100 - x)% 의 사용자는 다른 지역 센터로 안내된다.
하지만 데이터 센터 중 하나가 오류가 나면 100% 사용자가 하나의 데이터 센터로 전달된다.

결국 다중 데이터 센터 아키텍처를 만들려면 몇 가지 기술적 난제를 해결해야 한다.
- 트래픽 우회: 올바른 데이터 센터로 트래픽을 보내는 효과적인 방법을 찾아야한다.
- 데이터 동기화: 데이터 센터 마다 별도의 데이터 베이스를 사용하고 있는 상황이라면, 장애가 자동으로 복구되어 트래픽이 다른 데이터베이스로 우회된다 해도, 해당 데이터 센터에는 찾는 데이터가 없을 수도 있다. 이런 상황을 막기 위해서는 데이터를 여러 데이터 센터에 걸쳐 다중화해야한다. 


시스템이 더 큰 규모로 확장하기 위해서는 시스템의 컴포넌트를 분리하여, 각기 독립적으로 확장될 수 있도록하여야 한다. 메시지 큐는 많은 실제 분산 시스템이 이 문제를 풀기 위해 채용하는 핵심 전략 중 하나다.

---
### 메시지 큐
메시지 큐는 메시지의 무손실을 보장하는, 비동기 통신을 지원하는 컴포넌트이다. 메시지의 버퍼 역할을 하며, 비동기적으로 전송한다. 

메시지 큐의 기본 아키텍처는 생산자/ 발행자라고 불리는 입력 서비스가 메시지를 만들어 메시지 큐에 발행한다. 큐에는 보통 소비자 혹은 구독자라 불리는 서비스 혹은 서버가 연결되어 있는데, 메시지를 받아 그에 맞는 동작을 수행하는 역할을 한다.

메시지 큐를 이용하면 서비스 또는 서버 간 결합이 느슨해져서, 규모 확장성이 보장되어야 하는 안정적 애플리케이션을 구성하기 좋다. 
생산자는 소비자 프로세스가 다운되어 있어도 메시지를 발행할 수 있고, 소비자는 생산자 서비스가 가용한 상태가 아니더라도 메시지를 수신할 수 있다.


---
### 로그, 메트릭 그리고 자동화
- 로그: 시스템의 오류와 문제들을 보다 쉽게 찾아낼 수 있게 한다. 에러 로그는 서버 단위로 모니터링 할 수도 있지만, 로그를 단일 서비스로 모아주는 도구를 활용하면 더 편리하게 검색하고 조회할 수 있다.
- 메트릭: 메트릭을 잘 수집하면 사업 현황에 관한 유용한 정보를 얻을 수도 있고, 시스템의 현재 상태를 손쉽게 파악할 수도 있다. 
  - 호스트 단위 메트릭: CPU, 메모리, 디스크 I/O에 관한 메트릭이 해당한다.
  - 종합 메트릭: 데이터 베이스 계층의 성능, 캐시 계층의 성능 
- 자동화: 시스템이 크고 복잡해지면 생산성을 높이기 위해 자동화 도구를 활용해야한다. 지속적 통합을 도와주는 도구를 활용하면 개발자가 만드는 코드가 어떤 검증 절차를 자동으로 거치도록 할 수 있어서 문제를 쉽게 검증할 수 있다.

---
### 데이터 베이스 규모 확장
수직적 확장에 대해서는 대충 비슷한 내용이 반복되므로 수평적 확장에 대해서 말하도록 하겠다.

**수평적 확장**
샤딩이라고 부르는데, 더 많은 서버를 추가함으로써 성능을 향상시킬 수 있도록 한다. 
샤딩은 대규모 데이터 베이스를 샤드라고 부르는 작은 단위로 분할하는 기술을 일컫는다. 모든 샤드는 같은 스키마를 쓰지만 샤드에 보관되는 데이터에는 중복이 없다.
샤딩 키는 파티션 키로도 불리는데, 데이터가 어떻게 분산될지 정하는 하나 이상의 칼럼으로 구성된다. 
샤딩 키를 정할 시에는 데이터를 고르게 분할 할 수 있도록 하는게 가장 중요하다.

- 데이터의 재샤딩
  - 재샤딩이 필요한 시점 
    - 데이터가 너무 많아져서 하나의 샤드로는 더 이상 감당하기 어려울 때
    - 샤드 간 데이터 분포가 균등하지 못하여 어떤 샤드에 할당된 공간 소모가 다른 샤드에 비해 빨리 진행될 때
  - 샤드 소진이라고도 불리는 이런 현상이 발생하면 샤드 키를 계산하는 함수를 변경하고 데이터를 재배치 해야한다.
- 유명 인사 문제: 핫스팟 키 문제라고도 불리는데, 특정 샤드에 질의가 집중되어 서버가 과부하가 걸리는 문제이다. 특정 트래픽이 걸리는 로우는 각기 다른 샤드에 분산시킬 필요가 있다.
- 조인과 비정규화: 하나의 데이터 베이스를 여러 샤드 서버로 쪼개고 나면, 여러 샤드에 걸친 데이터를 조인하기가 힘들어진다. 
이를 해결하기 위해서는 결국 비정규화하여 테이블 하나로 질의가 수행될 수 있도록 하는 것이다.

<br>
<br>


# 정리
- 웹 계층은 무상태 계층으로
- 모든 계층에 다중화 도입
- 가능한 많은 데이터를 캐시할 것
- 여러 데이터 센터를 지원할 것
- 정적 콘텐츠는 CDN을 통해서 서비스할 것
- 데이터 계층은 샤딩을 통해 그 규모를 확장할 것
- 각 계층은 독립적 서비스로 분할할 것
- 시스템을 지속적으로 모니터링하고, 자동화 도구들을 활용할 것

개인적으로 느낀 바는 웹 계층의 다중화 같은 경우는 무상태 계층가 로드 밸런서를 통해서 가능하다는 것이 직관적으로 보인다.
하지만 DB 서버에 대한 다중화 혹은 캐시 계층에 대한 다중화 같은 경우 **어떤 식으로 일관성을 유지해 줄 것인가**를 핵심적으로 생각할 필요가 있을 것 같다. 물론 캐시 같은 경우 어느 정도 일관성을 무시하고 보여주는 방법도 있지만 DB 같은 경우는 중요한 데이터일 확률이 높으므로 어떤 식으로 일관성을 유지시킬 것인가에 대해서 한 번 고민해보고 글을 정리해보도록 하겠다.

# 출처
가상 면접 사례로 배우는 대규모 시스템 설계 기초
https://product.kyobobook.co.kr/detail/S000001033116
