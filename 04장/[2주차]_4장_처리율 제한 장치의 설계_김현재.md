# 처리율 제한 장치란?
처리율 제한 장치는 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치다. 
HTTP 를 예로 들면 이 장치는 특정 기간 내에 전송되는 클라이언트의 요청 횟수를 제한한다. API 요청 횟수가 제한 장치에 정의된 임계치를 넘어서면 추가로 도달한 모든 호출은 처리가 중단 된다. 

예를 들어
- 사용자는 초당 2회 이상 새 글을 올릴 수 없다.
- 같은 IP 주소로는 하루에 10개 이상의 계정을 생성할 수 없다.
- 같은 디바이스로는 주당 5회 이상 리워드를 요청할 수 없다.

<br>

**처리율 제한 장치를 둘때 장점은 무엇이 있을까?** 
- Dos 공격에 의한 자원 고갈을 방지할 수 있다. 
- 비용을 절감한다.
- 서버과부하를 막는다.

<br>
<br>

---

# 고려할 점
고려할 점을 모두 제시하지는 않았지만 책에서는 아래와 같은 정보에 대해서 먼저 확인해 볼 것을 제한하고 있다. 
- 클라이언트 측 제한 장치인지 서버 측 제한 장치인지? 
  - 둘 다 적절하게 혼용하는 편이 좀 더 효율적인 설계가 가능할 것이다. 
  - 아무래도 서버 측으로 가는 것 보다 클라이언트 측에서 제한할 수 있다면 좀 더 시간적 이득을 볼 수 있을 것 같다.(사견)
- API 호출 제한 시 어떤 기준을 잡을 것인가? 
  - IP 주소 기준
  - 사용자 ID
  - 기타 등등 
- 시스템 규모 
- 시스템이 분산 환경인가? 

<br>

**요구사항**
- 설정된 처리율을 초과하는 요청을 정확하게 제한한다.
- 낮은 응답 시간
- 가능한 적은 메모리 사용
- 분산형 처리율 제한
- 예외 처리: 요청이 제한 될 시 그 사실을 사용자에게 분명하게 보여줄 수 있어야한다.
- 높은 결함 감내성: 제한 장치에 장애가 생기더라도 전체 시스템에 영향을 주어서는 안된다.

<br>
<br>

---

# 개략적 설계안

**처리율 제한 장치의 위치**
- 클라이언트에 두는 경우: 일반적으로 클라이언트는 처리율 제한 장치를 안정적으로 걸 수 있는 장소가 아니다. 클라이언트는 쉽게 위변조가 가능하기 때문이다.
![](https://velog.velcdn.com/images/khjmr98/post/c1b1cc3c-5195-4606-82d2-e372d74304bd/image.png)
- 서버 측에 둔다면: 서버 측에 제한 장치를 두는 한 가지 방법을 
![](https://velog.velcdn.com/images/khjmr98/post/d9fb257c-284e-470e-9c61-25b8257deb50/image.png)
- 미들웨어 : 해당 미들웨어로 하여금 API 서버로 가는 요청을 통제하도록 하는 것이다.

**상황 가정**
![](https://velog.velcdn.com/images/khjmr98/post/8d383e52-842e-49c9-bb58-acc3a03a6b17/image.png)

API 서버 처리율이 초당 2개로 제한 되었다고 가정할 때 세 번 째 요청이 들어온다면 세 번째 요청은 미들웨어에 의해 가로막히고 HTTP 상태 코드 429가 반환될 것이다. HTTP 상태 코드 429는 사용자가 너무 많은 요청을 보내려고 했음을 알린다. 

보통 클라우드 마이크로 서비스의 경우, 처리율 제한 장치는 보통 API 게이트웨이라 불리는 컴포넌트에 구현된다. 이 부분이 궁금해서 좀 찾아보니 [AWS 에 관련 글](https://docs.aws.amazon.com/ko_kr/apigateway/latest/developerguide/api-gateway-request-throttling.html)이 존재하는 것을 확인할 수 있었다. 


>
>
API 게이트 웨이는 처리율 제한, SSL 종단, 사용자 인증, IP 허용 목록 관리 등을 지원하는 완전 위탁 관리형 서비스, 즉 클라우드 업체가 유지 보수를 담당하는 서비스다.
역할에 대해서 자세히 알아보고 싶다면 다음 [링크](https://bcho.tistory.com/1005)를 한 번 읽어보는 것도 좋을 것 같다. 흥미롭게 읽을 수 있는 글인 것 같습니다.

처리율 제한 장치를 서버에 둘 지 게이트 웨이에 둘 지는 전적으로 서비스의 성격에 달렸다. 

- 프로그래밍 언어, 캐시 서비스 등을 고려해야한다. 프로그래밍 언어가 서버 측 구현을 지원하기 충분할 정도로 효율이 높은지 확인하자.
- 여러 분의 사업 필요에 맞는 처리율 제한 알고리즘을 찾아라. 서버 측에서 모든 것을 구현하기로 했다면, 알고리즘은 자유롭게 선택 가능하다. 하지만 제 3자가 제공하는 게이트웨이를 사용하기로 했다면 선택지는 제한된다. 
예를 들어 AWS같은 경우는 토큰 버킷 알고리즘을 사용하여 API 서비스를 제한한다.
- 마이크로 서비스 기반의 설계이며, 사용자 인증이나 IP 허용 목록 관리 등을 처리하기 위해 API 게이트 웨이를 이미 설계에 포함시켰다면 처리율 제한 기능 또한 게이트 웨이에 포함시켜야 할 수도 있다.
- 처리율 제한 서비스를 직접 만드는데 시간이 들기 때문에 그냥 기존에 존재하는 서비스를 이용하는 것이 최선일 수도 있다.
<br>
<br>

---

# 처리율 제한 알고리즘
- 토큰 버킷 
- 누출 버킷
- 고정 윈도 카운터
- 이동 윈도 로그
- 이동 윈도 카운터


### 토큰 버킷
토큰 버킷은 처리율 제한에 폭 넓게 이용되고 있다. 

- 토큰 버킷은 지정된 용량을 갖는 컨테이너다. 이 버킷에는 사전 설정된 양의 토큰이 주기적으로 채워진다. 토큰이 꽉 찬 버킷에는 더 이상의 토큰은 추가되지 않는다. 버킷에는 토큰 2개가 추가된다. 버킷이 가득차면 추가로 공급된 토큰은 버려진다. 

- 각 요청은 처리될 때마다 하나의 토큰을 사용한다. 요청이 도착하면 버킷에 충분한 토큰이 있는지 검사하게 된다. 
  - 충분한 토큰이 있는 경우, 버킷에서 토큰 하나를 꺼낸 후 요청을 시스템에 전달한다. 
  - 충분한 토큰이 없는 경우, 해당 요청은 버려진다.
![](https://velog.velcdn.com/images/khjmr98/post/5a7c0b80-d2b6-4b1d-b9ac-497acad4dc2e/image.png)

<br>
<br>
<br>


실제 서비스 가정하고 러프한 시나리오를 그릴 수 있다.
![](https://velog.velcdn.com/images/khjmr98/post/185b05ac-db7f-4127-ba51-d16d29bdda5a/image.png)
1. 4개 토큰으로 시작한다. 하나의 요청이 올 시 토큰이 하나 빠진다.
2. 토큰이 3개 남는다. 이 때 3개의 요청이 올 시 모든 토큰이 소진된다.
3. 토큰은 0개이다. 따라서 요청은 무시된다.
4. 1분이 지나서 다시 토큰이 4개가 지급된다.

토큰 버킷 알고리즘에는 2개의 인자가 필요하다.
- 버킷 크기: 버킷에 담을 수 있는 토큰의 최대 개수
- 토큰 공급률: 초당 몇 개의 토큰이 버킷에 공급되는가?

공급 제한 규칙에 따라 버킷을 몇 개사용할지에 대해서도 다르게 적용할 수 있다.

- 통상적으로 API 엔드 포인트마다 별도의 버킷을 둔다. 
예를 들어 친구 추가 API, 포스팅 API 마다 별도의 제한 요건이 필요하다면 2개의 버킷이 필요할 것이다.
- IP 주소 별로 처리율 제한이 필요하다면 IP 주소마다 버킷을 하나 씩 할당한다.
- 시스템의 처리율을 초당 10,000 개 요청으로 제한하고 싶다면, 모든 요청이 하나의 버킷을 공유하도록 해야 한다.

**장점**
- 구현이 쉽다.
- 메모리 사용 측면에서도 효율적이다.
- 짧은 시간에 집중되는 트래픽에도 처리 가능하다. 버킷의 토큰 여부만 확인해도 요청은 시스템에 전달된다.

**단점**
- 인자를 적절하게 튜닝하는 것이 어려울 수도 있다.


### 누출 버킷 알고리즘
토큰 버킷 알고리즘과 비슷하지만 누출 버킷 알고리즘은 요청 처리율이 고정되어 있다는 점이 다르다. 누출 버킷 알고리즘은 보통 FIFO 큐로 동작한다.
![](https://velog.velcdn.com/images/khjmr98/post/df0f267d-bef8-45b8-bf4e-020b7907c421/image.png)

- 요청이 도착하면 큐가 가득 차 있는지 본다. 빈자리가 있는 경우에는 큐에 요청을 추가한다.
- 큐가 가득 차 있는 경우에는 새 요청은 버린다.
- 지정된 시간마다 큐에서 요청을 꺼내어 처리한다.
<br>

누출 버킷의 인자는 총 2가지가 사용된다.
- 버킷 크기: 큐사이즈와 같은 값이다. 큐에는 처리될 항목들이 보관된다.
- 처리율: 지정된 시간당 몇 개의 항목을 처리할지 지정하는 값이다.

<br>
다음과 같은 장단점을 가진다.

**장점**
- 큐의 크기가 제한되어 메모리 사용량 측면에서 효율적이다.
- 고정된 처리율을 갖고 있기 때문에 안정적 출력이 필요한 경우 적합하다.

**단점**
- 단시간에 많은 트래픽이 몰리는 경우 큐에는 오래된 요청들이 쌓이게 되고, 그 요청들을 제때 처리 못하면 최신 요청들이 버려지게 된다.
- 두 개 인자를 갖고 있는데, 이들을 올바르게 처리하기 힘들 수 있다.

<br>
---

### 고정 윈도 카운터 알고리즘
- 타임라인을 고정된 간격의 윈도로 나누고, 각 위도마다 카운터를 붙인다.
- 요청이 접수될 때마다 이 카운터의 값은 1씩 증가한다.
- 이 카운터의 값이 사전에 설정된 임계치에 도달하면 새로운 요청은 새로운 윈도가 열릴 때까지 버려진다.

![](https://velog.velcdn.com/images/khjmr98/post/7c3fc34c-f5a2-41f0-86d2-bb9611f2243b/image.png)
1분 사이에 최대 요청이 5개인 시스템이라고 가정했을 때 위와 같이 매 분마다 카운터가 리셋된다고 가정하면 1분 사이에 순간적으로 10개의 요청이 들어올 수 있는 문제가 생길수 있다.
허용한도의 2배의 요청이 순간적으로 들어오게 되는 것이다.

다음과 같은 장단점을 가진다.

**장점**
- 메모리 효율이 좋다.
- 이해하기 쉽다.
- 윈도가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기 좋다. -> 이 말은 좀 헷갈린다. 추후 정리 필요하다.

**단점**
- 윈도 경계 부근에서 일시적으로 많은 트래픽이 몰려드는 경우, 기대했던 시스템의 처리 한도보다 많은 양의 요청을 처리하게 된다.

<br>
<br>

---
### 이동 윈도 로깅 알고리즘
이동 윈도 로깅 알고리즘은 위에서 발생한 문제를 해결하기 위해서 다음과 같은 동작 원리를 제공한다.

- 이 알고리즘은 요청의 타임 스탬프를 추적한다. 타임 스탬프 데이터는 보통 Redis 의 정렬 집합 같은 캐시에 보관한다.
- 새 요청이 오면 만료된 타임 스탬프는 제거한다. 만료된 타임 스탬프는 현재 위도의 시작지점보다 오래된 타임스탬프를 말한다.
- 새 요청의 타임 스탬프를 로그에 추가한다.
- 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달한다. 그렇지 않은 경우에는 처리를 거부한다.


>
>
Redis의 정렬 집합이란? 
Redis 의 Z-set 이라는 자료구조를 통해 보통 구현된다. 이를 통해서 value 에 가중치를 부여해 순위를 매길 수 있게 된다. 이 경우에는 각 요청에 대해서 시간을 통해서 순서를 매길 수 있다는 점에서 메리트가 존재한다.

![](https://velog.velcdn.com/images/khjmr98/post/415263e2-f3fd-44bb-9bc0-35833ffd5aae/image.png)

장단점은 다음과 같다.

**장점**
- 이 알고리즘이 구현하는 처리율 제한 메커니즘은 아주 정교하다. 어느 순간의 윈도를 보더라도, 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 않는다.

**단점**
- 이 알고리즘은 다량의 메모리를 사용하는데, 거부된 요청의 타임스탬프도 보관하기 때문이다.

### 이동 윈도 카운터 알고리즘 
이동 윈도 카운터 알고리즘은 고정 윈도 카운터 알고리즘과 이동 윈도 로깅 알고리즘을 결합한 것이다. 

처리율 제한 장치 한도가 분당 7개 요청으로 설정되어 있다고 가정할 때, 이전 1분 동안 5개의 요청이, 그리고 1분 동안 3개의 요청이 왔다고 가정해보자. 현재 1분의 30% 시점에 도착한 새 요청의 경우, 현재 윈도에 몇 개의 요청이 온 것으로 보고 처리해야 할까?

- 현재 1분간의 요청 수 + 직전 1분간의 요청 수 * 이동 윈도와 직전 1분이 겹치는 비율
- 이 공식에 따르면 현재 윈도에 들어있는 요청은 3 + 5*70%= 6.5개다. 반올림해서 쓸 수도 있고 내림하여 쓸 수도 있는데, 본 예제에서 내림하여 쓰겠다. 따라서 그 값은 6이다.

장점과 단점은 다음과 같다.

**장점**
- 이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 계산하므로 짧은 시간에 몰리는 트래픽에도 잘 대응한다.
- 메모리 효율이 좋다.

**단점**
- 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기 때문에 다소 느슨하다. 



### 개략적 아키텍처

결국 Counter를 통해서 지금까지 온 요청을 어떤 식으로든 기록해야한다. 이 때 카운터를 어디에 보관해야 하는가가 주요한 문제가 된다. 

메모리 상에서 동작하는 캐시가 속도면에서나 만료 정책에서나 실제 구현을 위한 데이터 베이스로 적합하다. Redis 같은 경우가 실제로 처리율 제한 장치를 구현할 때 자주 사용된다고 한다. 

Redis 는 Single Thread이기 때문에 어느정도 원자적 동작을 보장할 뿐더러 Luna script 를 통해서 하나의 트랜잭션을 구성해 줄 수 있기 때문에 적합할 것 같다는 생각이 들었다. 

![](https://velog.velcdn.com/images/khjmr98/post/1f3eb7a9-e1dd-4313-8df9-5f8dfc91095b/image.png)

- 클라이언트의 요청은 처리율 제한 미들웨어로 향한다.
- 처리율 제한 미들웨어는 레디스의 지정 버킷에서 카운터를 가져와서 한도에 도달했는지 아닌지를 검사한다.
  - 한도에 도달했다면 요청은 거부된다.
  - 한도에 도달하지 않았다면 요청은 API 서버에 전달된다. 한편 미들웨어는 카운터의 값을 증가시킨 후 다시 레디스에 저장한다.

<br>
<br>


# 분산 환경에서 처리율 제한 장치 구현
여러 대의 서버와 병렬 스레드를 지원하도록 시스템을 확장하는 것은 두 가지 문제에 대해 고려해야한다.

- 경쟁조건 
- 동기화
<br>

### 경쟁 조건

- Redis 에서 카운터 값을 읽는다. 
- counter + 1이 임계치 값을 넘는지 확인
- 넘지 않는다면 레디스에 보관된 카운터 값을 1만큼 증가

병렬 스레드 환경에서는 두 개의 요청이 동시에 일어날 시 race condition 이 발생할 수 있고 counter라는 공유 자원에 대해서 의도하지 않은 값이 나올 수도 있게된다.

경쟁 조건에 대해서는 가장 흔한 해결책은 락(lock)이다. 하지만 락은 시스템 성능을 상당히 떨어뜨린다는 문제가 있다. 이 경우 루아 스크립트 혹은 Redis 의 정렬집합(Z-set)이라는 자료 구조를 쓰는 것이 해결책이 될 수 있을 것이다.

루아 스크립트를 쓰는게 왜 해결 책일지 궁금해서 찾아본 결과 루아 스크립트는 하나의 트랜잭션으로 Redis 의 명령어 단위를 묶어 줄 수 있고 따라서 경쟁조건에 대해서 애초에 배제 될 수 있기 때문에 사용가능한 것 같다. 

>
>
Lua script 관련 링크 참조 
https://velog.io/@injoon2019/Redis-%EB%A0%88%EB%94%94%EC%8A%A4-%ED%81%B4%EB%9D%BC%EC%9D%B4%EC%96%B8%ED%8A%B8%EC%99%80-%EB%B6%84%EC%82%B0%EB%9D%BD-6qg6tcwa


### 동기화 이슈
수백만 사용자를 지원하려면 한 대의 처리율 제한 장치로는 충분하지 않을 수도 있다. 따라서 처리율 제한 장치 서버를 여러 대 두게 될텐데 이 경우 동기화 문제가 발생할 수 있다. 

![](https://velog.velcdn.com/images/khjmr98/post/2a1192df-ebab-4aad-a08e-b860e37a1ac6/image.png)

한 가지 해결책은 고정 세션을 활용하여 같은 클라이언트로부터의 요청은 항상 같은 처리율 제한 장치로 보낼 수 있도록 하는 것이다. 이 방법은 하나의 처리율 제한 장치가 고장날 시 기존 세션을 잃어버리게 되므로 고장에 대해 유연하게 반응이 안될 뿐더러 로드 밸런싱이 제대로 이루어지지 않을 가능성이 있기 때문에 썩 좋은 방법은 아니라고 생각한다. 

따라서 Redis 와 같은 중앙 집중형 데이터 저장소를 쓰는 것이 좀 더 권장 되는 방법이다. 이러면 Redis 에 부하가 생길 수도 있기 때문에 Redis 를 Scale out 할 수 있는 방법에 대해서도 결국 생각해 볼 필요가 있을 것 같다. 
<br>


### 성능 최적화
 여러 데이터 센터를 지원하는 문제는 처리율 제한 장치에 매우 중요한 문제다. 데이터 센터에서 멀리 떨어진 사용자를 지원하려다 보면 지연 시간이 증가할 수 밖에 없기 때문이다. 
 제한 장치 간에 데이터를 동기화할 때 최종 일관성 모델을 사용해야한다. 이 방법은 다음 포스팅에서 고려해보겠다.
 
 
# 이 외의 고려할 점 
- 경성 또는 연성
  - 경성: 요청의 개수는 임계치를 절대 넘어설 수 없다.
  - 연성: 요청 개수는 잠시 동안은 임계치를 넘어설 수 있다.
  
- 다양한 계층에서의 처리율 제한 
  - 애플리케이션 계층에서의 처리율 제한이 아닌 다른 계층에서도 처리율 제한이 가능하다. 
  - 대표적으로 3계층에서 Iptables 를 사용하면 IP 주소에 처리율 제한을 적용하는 것이 가능하다.
- 처리율 제한 회피 방법. 클라이언트를 어떻게 설계하는 것이 최선인가? 
  - 클라이언트 측 캐시를 사용하여 API 호출 횟수를 줄이자.
  - 처리율 제한의 임계치를 이해하고, 짧은 시간 동안 너무 많은 메시지를 보내지 않도록 한다.
  - 예외나 에러를 처리하는 코드를 도입하여 클라이언트가 예외적 상황으로부터 우아하게 복구될 수 있도록 한다.
  - 재시도 로직을 구현할 때는 충분한 백오프 시간을 둔다.


# 출처

[가상 면접 사례로 배우는 대규모 시스템 설계 기초](https://product.kyobobook.co.kr/detail/S000001033116)
