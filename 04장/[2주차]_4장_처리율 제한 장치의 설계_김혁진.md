# 처리율 제한 장치의 설계
📌 **처리율 제한장치란?**
- 클라이언트 또는 서비스가 보내는 트래픽의 처리율(rate)을 제어하기 위한 장치.
- 즉 API 요청 횟수가 제한 장치에 임계치를 넘어서면 이외의 모든 호출은 중단(block)된다.
ex) HTTP에서 특정 기간 내에 전송되는 클라이언트의 요청 횟수를 제한.
  - 사용자는 초당 2회 이상 새글을 올릴 수 없다.
  - 같은 IP 주소로는 하루에 10개 이상의 계정을 생성할 수 없다.

✨ **처리율 제한 장치 사용의 이점**
1. Dos공격에 의한 자원 고갈을 방지할 수 있다(많은 요청으로 서버의 동작을 마비시키는 공격)
2. 비용 절감 : 추가 요청에 대한 처리를 제한하면 더 많은 자원을 필요한 API들에 할당해 줄 수 있다.
3. 서버 과부하를 막음 : bot에서 오는 트래픽이나 사용자의 잘못된 패턴으로 유발된 트래픽을 걸러낼 수 있다.

## 처리율 제한 장치 설계의 과정
### 1단계 문제 이해 및 설계 범위 확정
처리율 제한 장치를 구현하는데 필요한 여러가지 알고리즘 확인

1. **고정 시간 윈도우(Fixed Window)** : 가장 단순한 형태로, 정해진 시간 간격 동안의 요청 수를 제한한다.
-> 1분동안 최대 100개의 요청을 허용
-> 단점 : 윈도우 경계에서 요청이 몰릴 수 있어 불균형 발생 가능.
2. **슬라이딩 윈도우(Sliding Window)** : 고정 시간 윈도우의 단점을 보완하기 위해, 요청의 타임 스탬프를 기록하고 현재 시간에서 일정 기간 동안의 요청수를 계산한다.
-> 더 정밀한 제어가능, 메모리 사용량 또한 증가
3. **슬라이딩 윈도우 로그** : 모든 요청의 타임스탬프를 로그에 기록하고, 혀재 시간에서 과거로 일정 시간 동안의 요청을 계산한다.
등.. 

면접관과 소통하며 실제 어떤 제한 장치를 구현해야 하는지 확인하기.

💡 **예시 질문**
1. 처리율 제한 장치를 설계해야 하나요? 클라이언트 측 제한 장치인가요? 서버 측 제안 장치 일까요?
-> 처리율 제한 장치의 범위 확인
2. 어떠한 기준으로 API 호출을 정의해야 하나요?(IP주소 기반, 사용자 ID, or else?)
-> 처리율 제한 장치의 기준 확인
3. 시스템 규모는 어느정도 되나요?
->  응답시간에 영향을 주면 안된다.
4. 처리율 제한 장치는 독립된 서비스인가요? 어플리케이션 코드에 포함될 수 있나요?
-> 제한 장치에 장애가 생기더라도 전체 시스템에 영향을 주어선 안된다.
5. 분산 환경에서 동작하나요?
-> 하나의 처리율 제한 장치를 여러 서버나 프로세스에서 공유할 수 있어야 한다.
6. 사용자의 요청이 처리율 제한 장치에 의해 걸러진 경우 사용자에게 사실을 알려야하나요?
-> 예외 처리 : 요청이 제한되었을 때는 그 사실을 사용자가 알아야 한다.

### 2단계 개략적 설계안 제시
📌 처리율 제한 장치의 위치
1. **클라이언트측에 위치**
    - 클라이언트 요청은 쉽게 위변조가 가능해서 처리율 제한을 안정적으로 걸 수 없다.
2. **서버 측에 위치**
![image](https://github.com/11th-SSAFY-19/large-scale-system-design/assets/80228712/c2aa567b-2125-40fa-9bfa-892136ee8570)

3. **미들웨어에 위치**
![image](https://github.com/11th-SSAFY-19/large-scale-system-design/assets/80228712/209a4816-b84f-4c72-818c-1443304116d0)
  - 초당 2개의 요청으로 제한된 상황에서, 3번째 요청을 두 요청과 같은 초범위에 전송할 때, 마지막 요청은 미들웨어에 의해 가로막혀 HTTP 상태코드 429가 반환된다.
  💡 429(Too Many Requests) : 요청이 너무 많을 시 반환되는 상태 코드.

클라우드 마이크로서비스 환경에서는 처리율 제한 장치는 보통 API 게이트웨이라 불리는 컴포넌트에 구성된다.

❓ **API GateWay**
모든 서버로의 요청을 단일 지점을 거쳐서 처리하도록 한다. 이를 통해 공통된 로직 처리나 인증 및 인가 처리, 라우팅 처리를 할 수 있다.
![image](https://github.com/11th-SSAFY-19/large-scale-system-design/assets/80228712/c3bcffe7-e552-4a67-9081-9a40f5e63bf5)

- 클라우드 업체가 유지 보수를 담당하는 서비스이다(**단, 여기서는 쉽게 처리율 제한을 지원하는 미들웨어라고만 알고 있으면 됨!**)

🔎 **그러면 어디에 처리율 제한 장치를 넣어야 할까?**
답은 없다. 현재의 상황에 맞춰서 잘 넣어야 함.
단, 처리율 제한 서비스를 직접 만드는 데는 시간이 드므로, 구현하기에 충분한 인력이 없다면 상용 API 게이트웨이를 쓰는 것이 바람직한 방법이다.

📌 **처리율 제한 알고리즘**
처리율 제한을 실현하는 알고리즘에는 여러가지가 있고 각자 다른 장단점을 가지고 있다. 각각의 알고리즘에 대해 알아보자.

✨ **토큰 버킷 알고리즘**
- 간단하고 처리율 제한에 폭넓게 이용되는 알고리즘이다(아마존, 스트라이프 등...)
- 동작 원리 : 
  1. 토큰 버킷은 지정된 용량을 갖는 컨테이너다.
  2. 사전 설정된 양의 토큰이 주기적으로 채워진다. 토큰이 꽉 찬 버킷에는 더이상의 토큰이 추가되지 않는다.
   ![image](https://github.com/11th-SSAFY-19/large-scale-system-design/assets/80228712/4123e8e7-5178-4dac-b919-c4ad17f88c1d)
      - 이는, 용량이 4인 버킷으로 토큰 공급기는 이 버킷에 매초 2개의 토큰을 추가한다.
      - 버킷이 가득 차면 추가로 공급된 토큰은 버려진다(overflow)
  3. 각 요청은 처리될 때마다 하나의 토큰을 사용한다. 요청이 도착하면 버킷에 충분한 토큰이 있는지 검사한다.
    ![image](https://github.com/11th-SSAFY-19/large-scale-system-design/assets/80228712/c1ef4621-4297-4ed9-912e-94f30fb08020)

    - 충분한 토큰이 있는 경우, 버킷에서 토큰 하나를 꺼낸 후 요청을 시스템에 전달한다.
    - 충분한 토큰이 없는 경우, 해당 요청은 버려진다(dropped)

💡 **토큰 버킷 알고리즘은 2개의 인자를 받아야 한다.**
  - 버킷 크기 : 버킷에 담을 수 있는 토큰의 최대 개수
  - 토큰 공급률 : 초당 몇개의 토큰이 버킷에 공급되는가

💡 **버킷은 몇개나 사용해야 하나?**
- 통상적으로 API 엔드포인트마다 별도의 버킷을 둔다.
  ex) 
  1. 하루에 한 번만 포스팅 할 수 있고, 친구는 150명까지 추가할 수 있고, 좋아요 버튼은 다섯번 까지만 누를 수 있다 => 사용자마다 3개의 버킷을 둠.
  2. IP 주소별로 처리율 제한을 적용해야 한다면 IP 주소마다 버킷을 하나씩 할당해야 한다.

  ❓ 그렇다면.. 실제 사용자가 많고, 처리해야될 API가 많다면 오버헤드가 너무 크지 않을까?

  - 맞다. 이를 해결하기 위해 다양한 방법을 고려해야한다.
  1. 샤딩 : API를 여러 그룹으로 나누고 각 그룹에 대해 하나의 버킷을 사용하여 오버헤드를 줄일 수 있다(전체 API에 대한 처리율 제한을 그룹 단위로 관리할 수 있다.)
  2. 분산형 버킷 관리 : 중앙 집중식 버킷 관리 대신 분산형으로 관리하여 개별 서버나 노드가 각자 버킷을 유지하도록 할 수 있다. 이를 통해 중앙 서버의 오버헤드를 줄일 수 있다.

💡 **장점**
1. 구현이 쉽다.
2. 메모리 사용 측면에서도 효율적이다.
3. 짧은 시간에 집중되는 트래픽도 처리가능하다. 버킷에 남은 토큰이 있기만 하면 요청은 시스템에 전달될 것이다.

💡 **단점**
1. 이 알고리즘은 버킷 크기와 토큰 공급률이라는 두 개 인자를 가지고 있는데, 이 값을 적절하게 사용하는 것이 까다롭다. 

**💊 예제**
![image](https://github.com/11th-SSAFY-19/large-scale-system-design/assets/80228712/b72b185b-c78a-47d7-8ed2-7950ce81245f)

- 토큰 버킷의 크기는 4이고, 분당 토큰의 공급률은 4이다
- 4개의 토큰으로 시작하고, 하나의 요청이 왔을 때 하나의 토큰으로 처리 가능.
- 3개의 토큰인 상태에서, 3개의 요청이 왔을 때 3개의 토큰으로 처리 가능.
- 이후, 0개의 토큰이 있을 때 오는 요청은 버려짐.
- 1분이 지나서 4개의 토큰이 다시 공급됨.

✨ **누출 버킷 알고리즘**
- 토큰 버킷 알고리즘과 유사하지만 요청 처리율이 고정되어 있다는 점이 다르다.
- 주로, FIFO큐로 구현된다.

- 동작 원리 :
  1. 요청이 도착하면 큐가 가득 차 있는지 본다. 빈자리가 있는 경우에는 큐에 요청을 추가한다.
  2. 큐가 가득 차 있는 경우에는 새 요청은 버린다.
  3. 지정된 시간마다 큐에서 요청을 꺼내어 처리한다.

![image](https://github.com/11th-SSAFY-19/large-scale-system-design/assets/80228712/38c513c5-3927-47a1-9ca8-5e011cef364d)

💡 **누출 버킷 알고리즘은 2개의 인자를 받아야 한다.**
  - 버킷 크기 : 큐 사이즈와 같은 값이다. 큐에는 처리될 항목들이 보관된다.
  - 처리율 : 지정된 시간당 몇 개의 항목을 몇 개의 항목을 처리할지 지정하는 값이다.
  
💡 **장점**
1. 큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적이다.
2. 고정된 처리율을 갖고 있기 때문에 안정적 출력이 필요한 경우 적합하다.

💡 **단점**
1. 단시간에 많은 트래픽이 몰리는 경우 큐에는 오래된 요청들이 쌓이게 되고, 그 요청들을 제때 처리 못하면 최신 요청들은 버려지게 된다.
2. 이 알고리즘은 버킷 크기와 처리율이라는 두 개 인자를 가지고 있는데, 이 값을 적절하게 사용하는 것이 까다롭다. 

❓ **누출 버킷 알고리즘에서 큐와 버킷을 하나로 하면 안돼요?**
-> 버킷 자체가 큐로 생성되어 있는 것 같음.

✨ **고정 윈도 카운터**
- 타임라인을 고정된 간격의 윈도(window)로 나누고, 각 윈도마다 카운터(counter)를 붙인다.
- 요청이 접수될 때마다 이 카운터의 값은 1씩 증가한다.
- 이 카운터 값이 사전에 설정된 임계치에 도달하면 새로운 요청은 새 윈도가 열릴 때까지 버려진다.

![image](https://github.com/11th-SSAFY-19/large-scale-system-design/assets/80228712/60569a1f-7cbc-4155-8482-30bc32c55ef3)
- 1초마다 윈도가 열리고, 초당 3개까지의 요청을 처리한다고 했을 때 위와 같은 처리율을 나타낼 수 있다.
- 단, 윈도의 경계 부근에 순간적으로 많은 트래픽이 집중될 경우 윈도에 할당된 양보다 더 많은 요청이 처리될 수 있다.

![image](https://github.com/11th-SSAFY-19/large-scale-system-design/assets/80228712/b4b47d93-3866-40e0-9a60-f25b328b7c7b)
- 위와 같이, 고정된 시간(1분)내에서는 각자 5개의 트래픽을 처리했지만 해당 범위를 경계 부근으로 축소할 경우 시간내에 2배에 달하는 10개의 트래픽이 처리된 걸 알 수 있다!

💡 **장점**
1. 메모리 효율이 좋다
2. 이해하기 쉽다.
3. 윈도가 닫히는 시점에 카운터를 초기화 하는 방식은 특정한 트래픽 패턴을 처리하기에 적합하다.

💡 **단점**
1. 윈도 경계 부근에 일시적으로 많은 트래픽이 몰려드는 경우, 한계보다 더 많은 트래픽을 처리하게 된다.

✨ **이동 윈도 로그**
고정 윈도 카운터 방식은 윈도 경계에 트래픽이 집중되는 경우 시스템에 설정된 한도보다 많은 요청을 처리하게 됨.
-> 이를 처리하기 위해 `이동 윈도 로깅 알고리즘` 사용!

- 요청의 타임스탬프를 추적한다. 타임 스탬프 데이터는 보통 레디스의 정렬 집합 같은 캐시에 보관한다.
- 새 요청이 오면 만료된 타임스탬프는 제거한다. 만료된 타임 스탬프는 그 값이 현재 윈도의 시작 시점보다 오래된 타임 스탬프를 말한다.
- 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달, 그렇지 않다면 처리를 거부함.
![image](https://github.com/11th-SSAFY-19/large-scale-system-design/assets/80228712/6cde526f-b11c-4dc2-b189-eb01ad3d1810)
  - 요청이 1:00:01에 도착했을 때, 로그는 비어있음. 따라서, 요청이 허용됨.
  - 새로운 요청이 1:00:30에 도착했을 때 로그에 타임스탬프가 추가되고, 허용값인 2보다 작으므로 요청이 허용됨.
  - 새로운 요청이 1:00:50에 도착했을 때 로그에 타임스탬프가 추가된다. 허용 한도보다 큰 값이므로 타임스탬프는 로그에 남지만 요청은 거부된다.
  - 새로운 요청이 1:01:40에 도착한다. [1:00:40, 1:01:40) 범위 안에 요청은 1분 윈도안에 있는 요청이지만, 이전의 요청은 만료된 요청 이므로 총 로그의 크기는 2. 따라서, 신규 요청을 받아들인다.

💡 **장점**
1. 구현하는 처리율 제한 메커니즘이 아주 정교하여, 어느 윈도를 보더라도, 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 않는다.

💡 **단점**
1. 알고리즘은 거부된 요청의 타임스탬프도 보관하기 때문에 다량의 메모리를 사용한다.


✨ **이동 윈도 카운터**
고정 윈도 카운터 알고리즘과 이동 윈도 로깅 알고리즘을 결합한 것이다. 

![image](https://github.com/11th-SSAFY-19/large-scale-system-design/assets/80228712/090249c9-1b12-42b6-b2aa-1847ca4caa94)
- 처리율 제한 장치의 한도가 분당 7개 요청으로 설정되어 있다고 하고, 이전 1분 동안 5개의 요청이, 이후 1분동안 3개의 요청이 왔다고 했을 때...
  - 현재 1분간 요청 수 + 직전 1분간 요청 수 X 이동 윈도와 직접 1분이 겹치는 비율
  - 이 공식에 따르면 현재 윈도에 들어있는 요청은 3+ 5*70% = 6.5개이다. 반올림하거나 내림이 모두 가능하다.
  - 위를 내림해서 6개라고 했을 때 총 요청이 7개이므로, 신규 요청을 받을 수 있다.
💡 **장점**
1. 이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 게산하므로 짧은 시간에 몰리는 트래픽에도 잘 대응한다.
2. 메모리 효율이 좋다.

💡 **단점**
1. 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기 때문에 다소 느슨하다. 단, 그렇게 큰 편은 아니라고 생각함!

📌 **개략적인 아키텍처**
![image](https://github.com/11th-SSAFY-19/large-scale-system-design/assets/80228712/5bc0bdb1-a436-4ee2-a055-d7af4f57fd03)
- 기본적으로, redis에 사용자 별로 api사용량을 추적할 수 있는 counter를 놓고 이를 `INCR(메모리에 저장된 카운터의 값을 1만큼 증가)`와 `EXPIRE(카운터에 타임아웃 값을 정하고 설정된 시간이 지나면 카운터는 자동으로 삭제)`방식으로 구성된다.


### 3단계 상세 설계
📌 **처리율 제한 규칙은 어떻게 만들어지고 어디에 저장되는가?**
```yaml
domain: messaging
descriptors:
  - key: message_type
    Value: marketing
    rate_limit:
      unit: day
      requests_per_unit: 5
```
위는 시스템이 처리할 수 있는 마케팅 메시지의 최대치를 하루 5개로 제한하고 있는 사례.
이러한 규칙들은 **보통 설정파일 형태로 디스크에 저장**된다.

📌 **처리율 한도 초과 트래픽의 처리?**
- 어떤 요청이 한도 제한에 걸리면 API는 HTTP 429 응답을 클라이언트에게 보낸다.
- 경우에 따라서는, 한도 제한에 걸린 메시지를 나중에 처리하기 위해 큐에 보관할 수도 있다.

💡 **처리율 제한 장치가 사용하는 HTTP 헤더**
- 자기 요청이 처리율 제한에 걸리고 있는지를 알기 위해서는 HTTP 응답 헤더에 처리율 제한 장치로부터 온 응답을 확인하면 된다.
```
X-Ratelimit-Remaining : 윈도 내에 남은 처리 가능 요청의 수
X-Ratelimit-Limit : 매 윈도마다 클라이언트가 전송할 수 있는 요청의 수
X-Ratelimit-Retry-After : 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림.
```

- 따라서, 사용자의 요청이 많을 시 429 too many requests 오류를 X-RateLimit-Retry-After 헤더와 함께 반환하면 된다.


📌 **상세 설계**
![image](https://github.com/11th-SSAFY-19/large-scale-system-design/assets/80228712/dceccdba-9e04-447e-a92a-077be520ba1a)
1. 처리율 제한 규칙은 디스크에 보관한다. 작업 프로세스는 수시로 규칙을 디스크에서 읽어 캐시에 저장한다.
2. 클라이언트가 요청을 서버에 보내면 처리율 제한 제한 미들웨어에 도달한다.
   - 처리율 제한 규칙을 캐시에서 가져온다 + 카운터 및 마지막 요청의 타임 스탬프를 레디스 캐시에서 가져온다.
   - 해당 요청이 처리율 제한에 걸리면 429, 아니면 API 서버로 요청을 보냄.

📌 **분산 환경에서의 처리율 제한 장치의 구현**
- 여러 대의 서버와 병렬 스레드를 지원하도록 시스템을 확장하기 위해서는 두가지 문제를 해결해야 한다.
`경쟁조건(Race Condition)` & `동기화(Synchronization)`

💡 **경쟁 조건**
- 처리율 제한 장치는 주로
  - redis에서 카운터 값을 읽는다(counter)
  - counter+1의 값이 임계치를 넘는지 본다.
  - 넘지 않는 다면 레디스에 보관된 카운터 값을 1만큼 증가시킨다.
  ![image](https://github.com/11th-SSAFY-19/large-scale-system-design/assets/80228712/ccac63bd-213e-4ac0-a0b5-8fc8738982eb)

  - 이를 해결하지 위해서는 lock을 써야될 지만, 시스템의 성능을 매우 떨어뜨린다는 문제가 있다.
  - 해결하기 위해 `루아 스크립트` 와 `정렬 집합`이라는 레디스 자료구조로 해결할 수 있다.

💡 **동기화 이슈**
- 수백만 사용자를 지원하려면 한 대의 처리율 제한 장치 서버로는 충분하지 못하므로 여러대의 처리율 제한 장치를 둬야한다.

![image](https://github.com/11th-SSAFY-19/large-scale-system-design/assets/80228712/8aaf03e1-5046-444e-af56-47733e11629e)

- 웹 계층은 각기 다른 제한장치로 보낼 수 있으므로, 이는 각 제한장치 별 처리율 제한을 올바르게 수행할 수 없을 것이다.
- 따라서, 한가지 해결책은 고정 세션(sticky session)을 활용하여 같은 클라이언트로부터 요청은 항상 같은 처리율 제한장치로 보내는 것이다.
  - 비효율적임!
- 더 좋은 방법 : 레디스와 같은 중앙 집중형 데이터 저장소를 쓰는 것이다.
  ![image](https://github.com/11th-SSAFY-19/large-scale-system-design/assets/80228712/4abd4c5e-42fc-49ce-8db7-84bac947af00)
  -> like 웹 무상태 계층을 고려했을 때 MongoDB로 세션 같은 정보를 저장하듯!
## 참조
이미지 참조 : 
https://devjun.tistory.com/m/497
https://velog.io/@claraqn/API-Gateway
